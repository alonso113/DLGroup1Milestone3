{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ac2f10",
   "metadata": {},
   "source": [
    "# Fake News Detection with DistilBERT\n",
    "\n",
    "Group 01\n",
    "- Alonso Geesink Anton ()\n",
    "- Claudio Vincenzo Catalano Leiva (claudio.catalano.leiva@alumnos.upm.es)\n",
    "- Seyit Ahmet Inci ()\n",
    "\n",
    "Deep Learning Course 2025/26 - Course Project: Exercise 2 - Fine-tuning the Model with Experimentation\n",
    "\n",
    "**Dataset**: [Fake News Detection Datasets](https://www.kaggle.com/datasets/emineyetm/fake-news-detection-datasets/data)\n",
    "\n",
    "**Code References using DistilBERT**:\n",
    "- https://www.kaggle.com/code/henryukwuoma/fake-and-real-news-distilbert\n",
    "- https://www.kaggle.com/code/shehabmagdy710/distilbert-fine-tuning-on-fake-news-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9be0c",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The cell below contains package installations that you should do whenever you first use this Jupyter notebook. Additionally, remember to download the dataset files (true.csv & fake.csv) and place them on a new folder named **data**.",
   "id": "29bbd53254b8d949"
  },
  {
   "cell_type": "code",
   "id": "4d4b8f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:43:41.984300Z",
     "start_time": "2025-11-24T17:42:17.906376Z"
    }
   },
   "source": [
    "# Install required packages if needed\n",
    "#!pip install transformers datasets  pandas numpy scikit-learn matplotlib seaborn tqdm accelerate\n",
    "#!pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (2.9.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 6.1/6.1 MB 62.4 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.1/4.1 MB 49.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torchvision) (2.3.5)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (2449.3 MB)\n",
      "     ---------------------------------------- 0.0/2.4 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.4 GB 68.4 MB/s eta 0:00:36\n",
      "     ---------------------------------------- 0.0/2.4 GB 68.4 MB/s eta 0:00:36\n",
      "      --------------------------------------- 0.0/2.4 GB 70.2 MB/s eta 0:00:35\n",
      "      --------------------------------------- 0.1/2.4 GB 70.4 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 0.1/2.4 GB 71.0 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 0.1/2.4 GB 70.2 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 0.1/2.4 GB 70.3 MB/s eta 0:00:34\n",
      "     - -------------------------------------- 0.1/2.4 GB 70.5 MB/s eta 0:00:34\n",
      "     -- ------------------------------------- 0.1/2.4 GB 70.9 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.1/2.4 GB 71.7 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.2/2.4 GB 71.1 MB/s eta 0:00:33\n",
      "     -- ------------------------------------- 0.2/2.4 GB 70.8 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.7 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.5 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.4 MB/s eta 0:00:32\n",
      "     --- ------------------------------------ 0.2/2.4 GB 70.7 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.1 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.0 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.3 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 0.3/2.4 GB 71.6 MB/s eta 0:00:31\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 71.9 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 71.6 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 0.3/2.4 GB 71.9 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 0.4/2.4 GB 71.9 MB/s eta 0:00:30\n",
      "     ------ --------------------------------- 0.4/2.4 GB 71.9 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 0.4/2.4 GB 71.6 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 0.4/2.4 GB 71.9 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 0.4/2.4 GB 71.9 MB/s eta 0:00:29\n",
      "     ------- -------------------------------- 0.4/2.4 GB 72.9 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 0.5/2.4 GB 73.8 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 0.5/2.4 GB 75.1 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 0.5/2.4 GB 75.8 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 0.5/2.4 GB 76.5 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 0.5/2.4 GB 77.2 MB/s eta 0:00:25\n",
      "     -------- ------------------------------- 0.5/2.4 GB 78.0 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 0.6/2.4 GB 78.0 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 0.6/2.4 GB 79.1 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 79.4 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 0.6/2.4 GB 81.0 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 0.6/2.4 GB 82.6 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 0.6/2.4 GB 83.8 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 0.7/2.4 GB 83.8 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 84.6 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 84.2 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 84.6 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 0.7/2.4 GB 83.8 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 0.7/2.4 GB 82.6 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 0.8/2.4 GB 81.0 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 0.8/2.4 GB 76.2 MB/s eta 0:00:23\n",
      "     ------------ --------------------------- 0.8/2.4 GB 75.5 MB/s eta 0:00:23\n",
      "     ------------ --------------------------- 0.8/2.4 GB 75.1 MB/s eta 0:00:23\n",
      "     ------------- -------------------------- 0.8/2.4 GB 74.8 MB/s eta 0:00:22\n",
      "     ------------- -------------------------- 0.8/2.4 GB 74.5 MB/s eta 0:00:22\n",
      "     ------------- -------------------------- 0.8/2.4 GB 73.8 MB/s eta 0:00:22\n",
      "     ------------- -------------------------- 0.8/2.4 GB 73.5 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 0.9/2.4 GB 72.9 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 0.9/2.4 GB 72.5 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 0.9/2.4 GB 71.9 MB/s eta 0:00:22\n",
      "     -------------- ------------------------- 0.9/2.4 GB 71.6 MB/s eta 0:00:22\n",
      "     --------------- ------------------------ 0.9/2.4 GB 71.6 MB/s eta 0:00:22\n",
      "     --------------- ------------------------ 0.9/2.4 GB 71.9 MB/s eta 0:00:21\n",
      "     --------------- ------------------------ 1.0/2.4 GB 71.9 MB/s eta 0:00:21\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 71.6 MB/s eta 0:00:21\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 72.2 MB/s eta 0:00:21\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 76.9 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 1.0/2.4 GB 77.6 MB/s eta 0:00:19\n",
      "     ----------------- ---------------------- 1.0/2.4 GB 78.0 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 78.3 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 79.1 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 1.1/2.4 GB 80.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.1/2.4 GB 80.2 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.1/2.4 GB 79.8 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 1.2/2.4 GB 79.8 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 79.4 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 79.0 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 1.2/2.4 GB 78.7 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 1.2/2.4 GB 78.7 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 1.2/2.4 GB 78.7 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 1.3/2.4 GB 78.3 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 1.3/2.4 GB 79.1 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 1.3/2.4 GB 79.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 1.3/2.4 GB 80.2 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 1.3/2.4 GB 80.6 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 1.3/2.4 GB 80.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 1.4/2.4 GB 80.6 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 1.4/2.4 GB 80.2 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 1.4/2.4 GB 81.0 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 1.4/2.4 GB 81.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 1.4/2.4 GB 81.8 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 1.4/2.4 GB 82.1 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 1.5/2.4 GB 82.6 MB/s eta 0:00:13\n",
      "     ------------------------ --------------- 1.5/2.4 GB 82.6 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 1.5/2.4 GB 82.6 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 1.5/2.4 GB 82.2 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 1.5/2.4 GB 82.1 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 1.5/2.4 GB 82.1 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 1.6/2.4 GB 82.2 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 1.6/2.4 GB 77.3 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 1.6/2.4 GB 76.5 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 1.6/2.4 GB 76.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 1.6/2.4 GB 76.2 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 1.6/2.4 GB 74.8 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 1.6/2.4 GB 73.5 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 1.6/2.4 GB 72.5 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 1.7/2.4 GB 71.3 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 1.7/2.4 GB 70.4 MB/s eta 0:00:12\n",
      "     --------------------------- ------------ 1.7/2.4 GB 70.1 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 1.7/2.4 GB 69.5 MB/s eta 0:00:11\n",
      "     ---------------------------- ----------- 1.7/2.4 GB 68.7 MB/s eta 0:00:11\n",
      "     ---------------------------- ----------- 1.7/2.4 GB 68.1 MB/s eta 0:00:11\n",
      "     ---------------------------- ----------- 1.7/2.4 GB 67.6 MB/s eta 0:00:11\n",
      "     ---------------------------- ----------- 1.8/2.4 GB 67.3 MB/s eta 0:00:11\n",
      "     ----------------------------- ---------- 1.8/2.4 GB 67.3 MB/s eta 0:00:11\n",
      "     ----------------------------- ---------- 1.8/2.4 GB 66.8 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 1.8/2.4 GB 66.5 MB/s eta 0:00:10\n",
      "     ----------------------------- ---------- 1.8/2.4 GB 69.3 MB/s eta 0:00:10\n",
      "     ------------------------------ --------- 1.8/2.4 GB 69.5 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 1.9/2.4 GB 69.2 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 1.9/2.4 GB 69.8 MB/s eta 0:00:09\n",
      "     ------------------------------ --------- 1.9/2.4 GB 70.1 MB/s eta 0:00:09\n",
      "     ------------------------------- -------- 1.9/2.4 GB 71.0 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 1.9/2.4 GB 71.6 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 1.9/2.4 GB 72.6 MB/s eta 0:00:08\n",
      "     ------------------------------- -------- 1.9/2.4 GB 72.6 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 2.0/2.4 GB 72.9 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 2.0/2.4 GB 72.5 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 2.0/2.4 GB 72.6 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 2.0/2.4 GB 71.6 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 2.0/2.4 GB 71.6 MB/s eta 0:00:07\n",
      "     --------------------------------- ------ 2.0/2.4 GB 71.6 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 2.0/2.4 GB 70.7 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 2.1/2.4 GB 70.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 2.1/2.4 GB 70.4 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.1/2.4 GB 69.8 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.1/2.4 GB 69.5 MB/s eta 0:00:06\n",
      "     ---------------------------------- ----- 2.1/2.4 GB 69.6 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 2.1/2.4 GB 69.8 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.1/2.4 GB 69.3 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.2/2.4 GB 69.0 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.2/2.4 GB 68.1 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.2/2.4 GB 66.8 MB/s eta 0:00:05\n",
      "     ----------------------------------- ---- 2.2/2.4 GB 66.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.2/2.4 GB 65.7 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.2/2.4 GB 65.5 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.2/2.4 GB 65.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.2/2.4 GB 65.0 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.2/2.4 GB 61.9 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 2.3/2.4 GB 61.6 MB/s eta 0:00:04\n",
      "     ------------------------------------- -- 2.3/2.4 GB 61.9 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.3/2.4 GB 61.9 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.3/2.4 GB 61.4 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 2.3/2.4 GB 61.9 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.3/2.4 GB 61.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.3/2.4 GB 61.6 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.4 GB 61.9 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.4 GB 61.9 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 2.4/2.4 GB 61.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 61.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 61.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 62.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.4/2.4 GB 63.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.4/2.4 GB 33.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 6.2/6.2 MB 54.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\claud\\pycharmprojects\\deeplearningupmgroup01\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "\n",
      "  Attempting uninstall: sympy\n",
      "\n",
      "    Found existing installation: sympy 1.14.0\n",
      "\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "    Uninstalling sympy-1.14.0:\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "  Attempting uninstall: torch\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "    Found existing installation: torch 2.9.1\n",
      "   ---------------------------------------- 0/4 [sympy]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "    Uninstalling torch-2.9.1:\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "      Successfully uninstalled torch-2.9.1\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   ---------- ----------------------------- 1/4 [torch]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   -------------------- ------------------- 2/4 [torchvision]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ------------------------------ --------- 3/4 [torchaudio]\n",
      "   ---------------------------------------- 4/4 [torchaudio]\n",
      "\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1. Initial Setup and Imports",
   "id": "c2a04ec81ccedce9"
  },
  {
   "cell_type": "code",
   "id": "62375bad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:23:47.267230Z",
     "start_time": "2025-11-24T19:23:41.347703Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility for torch and numpy in our machines\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Device configuration -> In our case since we have a transformer mode if you guys have a gpu to use it will be faster\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using the following device for our training: {device}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following device for our training: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8c9da945",
   "metadata": {},
   "source": [
    "## 2. Loading the Data from the Kaggle Dataset\n",
    "\n",
    "Note: Before running this for our training, remember to check that the data files are in your local folder! You can find them from the dataset from Kaggle and place the CSV files in a `data/` directory.\n",
    "Expected files:\n",
    "- `Fake.csv`: Contains fake news articles\n",
    "- `True.csv`: Contains true news articles"
   ]
  },
  {
   "cell_type": "code",
   "id": "70d70340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:23:49.705592Z",
     "start_time": "2025-11-24T19:23:48.836284Z"
    }
   },
   "source": [
    "# Load the dataset which is split into two files: Fake.csv and True.csv\n",
    "fake_df = pd.read_csv('data/Fake.csv')\n",
    "true_df = pd.read_csv('data/True.csv')\n",
    "\n",
    "# Add labels: 0 for fake, 1 for true\n",
    "fake_df['label'] = 0\n",
    "true_df['label'] = 1\n",
    "\n",
    "# Combine the datasets so that we just have one file\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset to ensure random distribution for our training\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# Basic info about the dataset\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Fake news: {len(fake_df)} ({len(fake_df)/len(df)*100:.2f}%)\")\n",
    "print(f\"True news: {len(true_df)} ({len(true_df)/len(df)*100:.2f}%)\")\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of the dataset: \")\n",
    "df.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 44898\n",
      "Fake news: 23481 (52.30%)\n",
      "True news: 21417 (47.70%)\n",
      "\n",
      "Dataset shape: (44898, 5)\n",
      "\n",
      "Columns: ['title', 'text', 'subject', 'date', 'label']\n",
      "\n",
      "First few rows of the dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               title  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
       "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
       "3  On Monday, Donald Trump once again embarrassed...          News   \n",
       "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
       "\n",
       "                  date  label  \n",
       "0    February 13, 2017      0  \n",
       "1       April 5, 2017       1  \n",
       "2  September 27, 2017       1  \n",
       "3         May 22, 2017      0  \n",
       "4       June 24, 2016       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>February 13, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 24, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "54e058d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:23:52.889886Z",
     "start_time": "2025-11-24T19:23:52.745530Z"
    }
   },
   "source": [
    "# Visualization of the dataset with label distribution using a count plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.title('Distribution of Fake (0) vs True (1) News in Dataset', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Type of news in dataset', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Amount in dataset')\n",
    "plt.xticks([0, 1], ['Fake News', 'True News'])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9610189b",
   "metadata": {},
   "source": "## 3. Data Preprocessing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this section, we will preprocess the data to prepare it for training. This includes combining relevant text fields and splitting the dataset into training, validation, and test sets that will be used later for model training and evaluation.",
   "id": "c2e7aaf5e4667a79"
  },
  {
   "cell_type": "code",
   "id": "7c5a463f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:01.682526Z",
     "start_time": "2025-11-24T19:23:55.360877Z"
    }
   },
   "source": [
    "# 1. Combine title and text into a single 'content' column\n",
    "if 'title' in df.columns and 'text' in df.columns:\n",
    "    df['content'] = df['title'] + ' ' + df['text']\n",
    "elif 'text' in df.columns:\n",
    "    df['content'] = df['text']\n",
    "elif 'title' in df.columns:\n",
    "    df['content'] = df['title']\n",
    "else:\n",
    "    # Find the text column\n",
    "    text_cols = [col for col in df.columns if col not in ['label', 'subject', 'date']]\n",
    "    if text_cols:\n",
    "        df['content'] = df[text_cols[0]]\n",
    "    else:\n",
    "        raise ValueError(\"Could not find text column in dataset\")\n",
    "\n",
    "# 2. Clean Reuters tags from the combined content\n",
    "import re\n",
    "\n",
    "def clean_reuters_tag(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    # Remove patterns like \"(Reuters) - \" or \" (Reuters) \"\n",
    "    s = re.sub(r'\\(?\\bReuters\\b\\)?\\s*-\\s*', '', s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r'\\(?\\bReuters\\b\\)?', '', s, flags=re.IGNORECASE)\n",
    "    return s.strip()\n",
    "\n",
    "df['content'] = df['content'].apply(clean_reuters_tag)\n",
    "\n",
    "# 3. Inspect average length after cleaning\n",
    "print(f\"Average content length: {df['content'].str.len().mean():.0f} characters\")\n",
    "\n",
    "print(\"Data preprocessing completed. Sample data:\")\n",
    "df[['content', 'label']].head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average content length: 2542 characters\n",
      "Data preprocessing completed. Sample data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                             content  label\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...      0\n",
       "1  Trump drops Steve Bannon from National Securit...      1\n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...      1\n",
       "3  OOPS: Trump Just Accidentally Confirmed He Lea...      0\n",
       "4  Donald Trump heads for Scotland to reopen a go...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Lea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e6151c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:03.457668Z",
     "start_time": "2025-11-24T19:24:03.410983Z"
    }
   },
   "source": [
    "# First split: 85% train+val, 15% test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df, test_size=0.15, random_state=SEED, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Second split: 82.35% train, 17.65% val from the train+val set\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, test_size=0.1765, random_state=SEED, stratify=train_val_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Training set size (70%): {len(train_df)}\")\n",
    "print(f\"Validation set size (15%): {len(val_df)}\")\n",
    "print(f\"Test set size (15%): {len(test_df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (70%): 31427\n",
      "Validation set size (15%): 6736\n",
      "Test set size (15%): 6735\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.5 - Defining the configurations",
   "id": "20de1a5409f74579"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In order to fine-tune our DistilBERT model for fake news detection, we will experiment with different hyperparameter configurations. Below are the configurations we will use for training, each with a unique combination of the following 3 hyperparameters: epochs, learning rate, and weight decay.\n",
    "\n",
    "**Combinations:**\n",
    "- **Config 1:** epochs=1, learning_rate=4e-5, weight_decay=0.00\n",
    "- **Config 2:** epochs=2, learning_rate=3e-5, weight_decay=0.01\n",
    "- **Config 3:** epochs=2, learning_rate=3e-5, weight_decay=0.005\n",
    "- **Config 4:** epochs=3, learning_rate=2e-5, weight_decay=0.01\n",
    "- **Config 5:** epochs=3, learning_rate=2e-5, weight_decay=0.015\n",
    "- **Config 6:** epochs=4, learning_rate=1.5e-5, weight_decay=0.02"
   ],
   "id": "f159376c774f58ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:06.526746Z",
     "start_time": "2025-11-24T19:24:06.521739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Global training constants -> batch size and output directory to save results\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 128\n",
    "OUTPUT_DIR = Path(\"DL_Milestone2_experiments\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# List of configurations with the following hyperparameters: epochs, learning_rate, weight_decay\n",
    "configs = [\n",
    "    {\"name\": \"1\", \"epochs\": 1,  \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 3e-5,  \"weight_decay\": 0.02},\n",
    "    {\"name\": \"2\", \"epochs\": 1, \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 1.5e-5,  \"weight_decay\": 0.02},\n",
    "    {\"name\": \"3\", \"epochs\": 2,  \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 3e-5,  \"weight_decay\": 0.02},\n",
    "    {\"name\": \"4\", \"epochs\": 2, \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 1.5e-5,\"weight_decay\": 0.02},\n",
    "    {\"name\": \"5\", \"epochs\": 3, \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 3e-5,  \"weight_decay\": 0.02},\n",
    "    {\"name\": \"6\", \"epochs\": 3,  \"per_device_train_batch_size\": BATCH_SIZE, \"learning_rate\": 1.5e-5,  \"weight_decay\": 0.02},\n",
    "]\n",
    "\n",
    "print(\"Loaded configurations for training:\")\n",
    "for cfg in configs:\n",
    "    print(cfg)"
   ],
   "id": "4748f41ec639b909",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configurations for training:\n",
      "{'name': '1', 'epochs': 1, 'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02}\n",
      "{'name': '2', 'epochs': 1, 'per_device_train_batch_size': 32, 'learning_rate': 1.5e-05, 'weight_decay': 0.02}\n",
      "{'name': '3', 'epochs': 2, 'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02}\n",
      "{'name': '4', 'epochs': 2, 'per_device_train_batch_size': 32, 'learning_rate': 1.5e-05, 'weight_decay': 0.02}\n",
      "{'name': '5', 'epochs': 3, 'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02}\n",
      "{'name': '6', 'epochs': 3, 'per_device_train_batch_size': 32, 'learning_rate': 1.5e-05, 'weight_decay': 0.02}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "035f8375",
   "metadata": {},
   "source": [
    "## 4. Tokenization and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "id": "bbe32943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:09.577883Z",
     "start_time": "2025-11-24T19:24:08.671608Z"
    }
   },
   "source": [
    "# Load DistilBERT tokenizer\n",
    "# Note: Using AutoTokenizer for better compatibility\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(f\"Tokenizer loaded: {MODEL_NAME}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: distilbert-base-uncased\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e9188bfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:11.023567Z",
     "start_time": "2025-11-24T19:24:11.020241Z"
    }
   },
   "source": [
    "# Define custom dataset class for our train, val, test sets\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=MAX_LENGTH):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_length,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9686e197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:13.356003Z",
     "start_time": "2025-11-24T19:24:13.351047Z"
    }
   },
   "source": [
    "# Create datasets for train, val, test\n",
    "train_dataset = FakeNewsDataset(\n",
    "    texts = train_df['content'].values,\n",
    "    labels = train_df['label'].values,\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = MAX_LENGTH\n",
    ")\n",
    "\n",
    "val_dataset = FakeNewsDataset(\n",
    "    texts = val_df['content'].values,\n",
    "    labels = val_df['label'].values,\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = MAX_LENGTH\n",
    ")\n",
    "\n",
    "test_dataset = FakeNewsDataset(\n",
    "    texts = test_df['content'].values,\n",
    "    labels = test_df['label'].values,\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = MAX_LENGTH\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 983\n",
      "Number of validation batches: 211\n",
      "Number of test batches: 211\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "6e4c10c9",
   "metadata": {},
   "source": [
    "## 5. Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e04d174e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:18.228277Z",
     "start_time": "2025-11-24T19:24:17.488868Z"
    }
   },
   "source": [
    "# Load pre-trained DistilBERT model with 2 output labels (fake, true)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded and moved to {device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and moved to cuda\n",
      "Number of parameters: 66,955,010\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "7b2258bf",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this implementation of the training loop, we define two key functions: `train_epoch` and `eval_model`. The `train_epoch` function handles the training process for one epoch, including forward and backward passes, loss calculation, and accuracy tracking. The `eval_model` function evaluates the model's performance on the validation or test set without updating the model weights. Both functions utilize progress bars for better visualization of the training and evaluation processes.\n",
    "\n",
    "We are not using huggingface's Trainer API to have more control over the training loop and to facilitate custom logging and metric tracking."
   ],
   "id": "c4983abd22b5acd9"
  },
  {
   "cell_type": "code",
   "id": "aeda32e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:21.130999Z",
     "start_time": "2025-11-24T19:24:21.126421Z"
    }
   },
   "source": [
    "# This function trains the model for one epoch\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Progress bar for visualization\n",
    "    progress_bar = tqdm(data_loader, desc='Training')\n",
    "\n",
    "    # Iterate over the batches in the data loader\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        # Move the batch to the specified device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass part of the training\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            labels = labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Backward pass and optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate accuracy for the batch\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_predictions += labels.size(0)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Update progress bar with current loss and accuracy\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'acc': (correct_predictions.double() / total_predictions).item()\n",
    "        })\n",
    "    \n",
    "    return correct_predictions.double() / total_predictions, np.mean(losses)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "aac57af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:26.059955Z",
     "start_time": "2025-11-24T19:24:26.054954Z"
    }
   },
   "source": [
    "# This function evaluates the model on the validation/test set. This does not update model weights and is done after each training epoch.\n",
    "def eval_model(model, data_loader, device):\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc='Evaluating')\n",
    "\n",
    "        # Iterate over the batches in the data loader\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                labels = labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Calculate accuracy for the batch\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            total_predictions += labels.size(0)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Store all predictions and labels for further analysis\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return (\n",
    "        correct_predictions.double() / total_predictions,\n",
    "        np.mean(losses),\n",
    "        np.array(all_preds),\n",
    "        np.array(all_labels)\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:24:28.617162Z",
     "start_time": "2025-11-24T19:24:28.613301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This function sets up the optimizer and scheduler for each configuration\n",
    "def setup_optimizer_and_scheduler(model, train_loader, learning_rate, weight_decay, epochs):\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8, weight_decay=weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    print(f\"Total training steps: {total_steps}\")\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Function to save run results so we can later analyze on SPSS\n",
    "def save_run_result(run_metadata: dict, metrics: dict, filename: str = None):\n",
    "    payload = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"config\": run_metadata,\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "    if filename is None:\n",
    "        safe_name = f\"run_{run_metadata['name']}_e{run_metadata['epochs']}_lr{run_metadata['learning_rate']}_wd{run_metadata['weight_decay']}.json\"\n",
    "        filename = OUTPUT_DIR / safe_name\n",
    "    else:\n",
    "        filename = OUTPUT_DIR / filename\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(payload, f, indent=2)\n",
    "    print(f\"Saved results to {filename}\")"
   ],
   "id": "27df3225877e45d3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "d6f5e427",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In our training loop, we can first define the config that we want to make the 5 runs of. These runs will be independent of each other, meaning that for each run we will reload the model and optimizer to ensure that the training starts from the same initial state. This is crucial for obtaining unbiased results when evaluating the performance of different hyperparameter configurations.\n",
    "\n",
    "Since we want to do 15 runs per configuration (5 runs each team member), we will loop over the number of runs and for each run, we will train the model for the specified number of epochs defined in the configuration. After training, we will evaluate the model on the validation set and save the best model based on validation accuracy."
   ],
   "id": "cecacfb9f037f29a"
  },
  {
   "cell_type": "code",
   "id": "b06250e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T01:20:44.022985Z",
     "start_time": "2025-11-24T19:24:32.738161Z"
    }
   },
   "source": [
    "# Training Loop over ALL configurations\n",
    "all_results = []\n",
    "\n",
    "print(\"Starting full experiment sweep over all configurations...\\n\")\n",
    "\n",
    "for cfg in configs:\n",
    "    config_num = cfg[\"name\"]\n",
    "\n",
    "    # Make directory for this configuration\n",
    "    config_dir = OUTPUT_DIR / f\"cfg{config_num}\"\n",
    "    config_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Starting run for CONFIG {cfg['name']} | \"\n",
    "          f\"epochs={cfg['epochs']}, lr={cfg['learning_rate']}, \"\n",
    "          f\"wd={cfg['weight_decay']}, batch_size={cfg['per_device_train_batch_size']}, \"\n",
    "          f\"device={device}, max_length={MAX_LENGTH}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Run 5 independent runs per config\n",
    "    for run in range(1, 7):\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Run {run}/5 for config {cfg['name']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        run_start_time = time.time()\n",
    "\n",
    "        # Reload model + optimizer to ensure independence\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME, num_labels=2\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer, scheduler = setup_optimizer_and_scheduler(\n",
    "            model,\n",
    "            train_loader,\n",
    "            learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'],\n",
    "            epochs=cfg['epochs'],\n",
    "        )\n",
    "\n",
    "        # Track metrics\n",
    "        history = {\n",
    "            \"train_acc\": [],\n",
    "            \"train_loss\": [],\n",
    "            \"val_acc\": [],\n",
    "            \"val_loss\": [],\n",
    "        }\n",
    "        epoch_times = []\n",
    "        best_val_acc = 0\n",
    "\n",
    "        # Epoch loop\n",
    "        for epoch in range(cfg['epochs']):\n",
    "            print(f\"Epoch {epoch + 1}/{cfg['epochs']}\")\n",
    "\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            train_acc, train_loss = train_epoch(\n",
    "                model, train_loader, optimizer, scheduler, device\n",
    "            )\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "            val_acc, val_loss, _, _ = eval_model(\n",
    "                model, val_loader, device\n",
    "            )\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            epoch_times.append(epoch_duration)\n",
    "            print(f\"Epoch time: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "            history[\"train_acc\"].append(train_acc.item())\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"val_acc\"].append(val_acc.item())\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                model_path = config_dir / f\"bestmodel_{cfg['name']}_run{run}.pt\"\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"> Best model saved with validation accuracy {best_val_acc:.4f}\")\n",
    "\n",
    "        # End of run\n",
    "        run_duration = time.time() - run_start_time\n",
    "        print(f\"Run time: {run_duration:.2f} seconds\")\n",
    "\n",
    "        metrics = {\n",
    "            \"history\": history,\n",
    "            \"epoch_times\": epoch_times,\n",
    "            \"run_time\": run_duration,\n",
    "            \"best_val_acc\": (\n",
    "                best_val_acc.item() if hasattr(best_val_acc, \"item\") else best_val_acc\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        save_run_result(\n",
    "            run_metadata=cfg,\n",
    "            metrics=metrics,\n",
    "            filename=f\"run_{cfg['name']}_{run}.json\"\n",
    "        )\n",
    "\n",
    "        all_results.append({\"config\": cfg, \"metrics\": metrics})\n",
    "\n",
    "print(\"\\nAll configurations completed successfully!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full experiment sweep over all configurations...\n",
      "\n",
      "============================================================\n",
      "Starting run for CONFIG 1 | epochs=1, lr=3e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0c70d046e8248b09765ecb328d5b864"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0309 | Train Acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92696cfe94d3457eace6b738624a6876"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0172 | Val Acc: 0.9966\n",
      "Epoch time: 293.88 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Run time: 294.88 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa51ddbf9f31401cb4927dbea675206e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330 | Train Acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fcafff63c1e433881ef2ccb87205a60"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0118 | Val Acc: 0.9972\n",
      "Epoch time: 301.08 seconds\n",
      "> Best model saved with validation accuracy 0.9972\n",
      "Run time: 302.48 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f200bb00e4fb404eb4d4294e708a0a23"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0314 | Train Acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3856acf326d24fb999f2554e54f9851f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0137 | Val Acc: 0.9966\n",
      "Epoch time: 298.39 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Run time: 300.00 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d05370d4e806440db37ceb3ddb770b70"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339 | Train Acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6137a3a4020e4aa69413f6e95df36066"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0123 | Val Acc: 0.9966\n",
      "Epoch time: 297.88 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Run time: 299.26 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae03a39f1e2041149fdb5342a1f005d7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0294 | Train Acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0735b420455949fca5a6870fde6b954b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0131 | Val Acc: 0.9966\n",
      "Epoch time: 297.24 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Run time: 298.45 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 1\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c24890d2ded04d7bbc701db7068226f1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0337 | Train Acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6841c643ce91413bb8970ef942914cc1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0103 | Val Acc: 0.9969\n",
      "Epoch time: 296.20 seconds\n",
      "> Best model saved with validation accuracy 0.9969\n",
      "Run time: 297.80 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_1_6.json\n",
      "============================================================\n",
      "Starting run for CONFIG 2 | epochs=1, lr=1.5e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3ef79ceab4840e7aa6ab24b510e3b09"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0431 | Train Acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b4d52fa78204325a4582d243b488604"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0180 | Val Acc: 0.9951\n",
      "Epoch time: 295.56 seconds\n",
      "> Best model saved with validation accuracy 0.9951\n",
      "Run time: 296.89 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1757d417b08e44249b599ae7b14ca2e9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0411 | Train Acc: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4539803248a0468783a1ad84cece7c7f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0164 | Val Acc: 0.9958\n",
      "Epoch time: 295.73 seconds\n",
      "> Best model saved with validation accuracy 0.9958\n",
      "Run time: 296.96 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dddabc576bf14fbf80c3e7de448aa4e2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0428 | Train Acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47aa6b162d384a77aa6324abeda5828b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0187 | Val Acc: 0.9954\n",
      "Epoch time: 296.12 seconds\n",
      "> Best model saved with validation accuracy 0.9954\n",
      "Run time: 297.30 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa0c94bd4e7b4d5d80989f8aa35f8791"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0436 | Train Acc: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbb9b5890b3e42319d56c94474d8d550"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0156 | Val Acc: 0.9958\n",
      "Epoch time: 296.11 seconds\n",
      "> Best model saved with validation accuracy 0.9958\n",
      "Run time: 297.25 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0db2a37ed10b48d9854fbf87ce4a4ce9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0446 | Train Acc: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73a29e6d11d04557af956e568d1f93d3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0211 | Val Acc: 0.9950\n",
      "Epoch time: 295.54 seconds\n",
      "> Best model saved with validation accuracy 0.9950\n",
      "Run time: 296.82 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 2\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 983\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6bcd853102e481b9686a759232384f7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0435 | Train Acc: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c9ccbe16c5b4cbf8a5dfc55e7691314"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0146 | Val Acc: 0.9964\n",
      "Epoch time: 296.09 seconds\n",
      "> Best model saved with validation accuracy 0.9964\n",
      "Run time: 297.54 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_2_6.json\n",
      "============================================================\n",
      "Starting run for CONFIG 3 | epochs=2, lr=3e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cfd36554f374691a7adb1c3f3a59daf"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0336 | Train Acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf807b6d6f38487aae9778bf94803590"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0151 | Val Acc: 0.9966\n",
      "Epoch time: 296.18 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f36c3d2c67e44846a8c1b6d649bdbe6f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0011 | Train Acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c4d94dda66e40f1afc052b6f8e0bef9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0144 | Val Acc: 0.9975\n",
      "Epoch time: 296.38 seconds\n",
      "> Best model saved with validation accuracy 0.9975\n",
      "Run time: 594.43 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5aa29ea4bece42c69229f8c3121de67d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0338 | Train Acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a66c699f450e40cc9c3fe4e91e43e67a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0056 | Val Acc: 0.9984\n",
      "Epoch time: 295.79 seconds\n",
      "> Best model saved with validation accuracy 0.9984\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccc1c002d3874befb65a59199ba65d1c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0023 | Train Acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d207750c99548329df53946e82a9be9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0083 | Val Acc: 0.9985\n",
      "Epoch time: 295.89 seconds\n",
      "> Best model saved with validation accuracy 0.9985\n",
      "Run time: 593.45 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b16b104ff9047c1b97c45cf4b4ba5e9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339 | Train Acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20425fa276f44308b6641d7569681682"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0127 | Val Acc: 0.9973\n",
      "Epoch time: 295.83 seconds\n",
      "> Best model saved with validation accuracy 0.9973\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f65226442d9145ac955498399b094a41"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0023 | Train Acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "770da8eb88cd4e4eb8465d92ae619d10"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0097 | Val Acc: 0.9981\n",
      "Epoch time: 296.15 seconds\n",
      "> Best model saved with validation accuracy 0.9981\n",
      "Run time: 593.66 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9cd06b4eee74f46bb448a01dec154a7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0328 | Train Acc: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a75226d49f2f42a19c6a0a1ba2d1d18f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0104 | Val Acc: 0.9976\n",
      "Epoch time: 295.81 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70e23385caf7424eae665b0433c5a83f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "decde0c1e9a2433bb04a9165b977453d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0108 | Val Acc: 0.9978\n",
      "Epoch time: 296.42 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Run time: 593.88 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1e694acbbee4bf294ba750a858f91cb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339 | Train Acc: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80c803911a5c48b59de54f030bb69e66"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0074 | Val Acc: 0.9976\n",
      "Epoch time: 295.44 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c097f44d96a04b7bb2dd1e81c4ca9e3d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfc7424b0fb04cf9994ae3679987ed7c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0066 | Val Acc: 0.9988\n",
      "Epoch time: 296.46 seconds\n",
      "> Best model saved with validation accuracy 0.9988\n",
      "Run time: 593.85 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c8ef354817a470ca0e820ddb514780b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0325 | Train Acc: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17dd0a6992104ba8bdc30714046be08e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0174 | Val Acc: 0.9966\n",
      "Epoch time: 295.80 seconds\n",
      "> Best model saved with validation accuracy 0.9966\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d67c22fc0eca4f8f822323a667d7ba4b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032 | Train Acc: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9eb948a610c4bb1b9a94fb9b6e798c0"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0112 | Val Acc: 0.9978\n",
      "Epoch time: 295.93 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Run time: 593.48 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_3_6.json\n",
      "============================================================\n",
      "Starting run for CONFIG 4 | epochs=2, lr=1.5e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2e1feaac1774644ae83576bbb56d0d4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0432 | Train Acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bbe45da62dd46ad87f8801aa5ada5f1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0128 | Val Acc: 0.9972\n",
      "Epoch time: 296.16 seconds\n",
      "> Best model saved with validation accuracy 0.9972\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c799bfb570f64299b2752124fe7c3937"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0033 | Train Acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b83c8d49f2144ae1863e9727afe23e39"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0132 | Val Acc: 0.9970\n",
      "Epoch time: 296.79 seconds\n",
      "Run time: 594.24 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4826f60a77c64eb5ad97bf025f8df685"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0421 | Train Acc: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6699cbe22824883b3198df80b3d93ff"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0137 | Val Acc: 0.9972\n",
      "Epoch time: 296.56 seconds\n",
      "> Best model saved with validation accuracy 0.9972\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f5dcd3347a47bf86d93867efe9f8d2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffc0e95702924c1b9fce1f34fc2fb5fa"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0125 | Val Acc: 0.9979\n",
      "Epoch time: 296.54 seconds\n",
      "> Best model saved with validation accuracy 0.9979\n",
      "Run time: 594.80 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7797f58c3aa4cfabe646b7b981e2505"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0453 | Train Acc: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4def2b42202e4533aea251717395b194"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0197 | Val Acc: 0.9951\n",
      "Epoch time: 295.55 seconds\n",
      "> Best model saved with validation accuracy 0.9951\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4548e29e350b4b4fb2ad83a089d7b9f8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0042 | Train Acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07723575a7d2458f8e093e05683c19db"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0160 | Val Acc: 0.9969\n",
      "Epoch time: 295.96 seconds\n",
      "> Best model saved with validation accuracy 0.9969\n",
      "Run time: 593.31 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a34116e7eecc416f90f9eed5929e4868"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0443 | Train Acc: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a00b2d94e87449469b1eef24fb7a79f1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0108 | Val Acc: 0.9970\n",
      "Epoch time: 295.26 seconds\n",
      "> Best model saved with validation accuracy 0.9970\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2613ab9873d843b1b0e34921f68b0a11"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032 | Train Acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "270a18cedbb94f589800a8a32bee079f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0118 | Val Acc: 0.9969\n",
      "Epoch time: 295.95 seconds\n",
      "Run time: 592.49 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e086b1923a9e486bbc0a15434bc838c4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0430 | Train Acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20745190ca9844868f9f034297ad9dce"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0168 | Val Acc: 0.9961\n",
      "Epoch time: 295.59 seconds\n",
      "> Best model saved with validation accuracy 0.9961\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ca426601414a4f8160e6c002638d6e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032 | Train Acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a77e2e6ad4d04e0f8cc38b6c107a6336"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0171 | Val Acc: 0.9970\n",
      "Epoch time: 295.87 seconds\n",
      "> Best model saved with validation accuracy 0.9970\n",
      "Run time: 593.32 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 1966\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7079768c8093457e87572d4b488ff43f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0461 | Train Acc: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8130c383d4ec41bab704a6a4e6fa1c00"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0189 | Val Acc: 0.9951\n",
      "Epoch time: 295.40 seconds\n",
      "> Best model saved with validation accuracy 0.9951\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e428a41d625143aabbfa554b6ec0b9c9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0037 | Train Acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26b170c3c88f4e7795b0ecad9e0e267b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0157 | Val Acc: 0.9964\n",
      "Epoch time: 295.07 seconds\n",
      "> Best model saved with validation accuracy 0.9964\n",
      "Run time: 592.39 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_4_6.json\n",
      "============================================================\n",
      "Starting run for CONFIG 5 | epochs=3, lr=3e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5585738950ee4146be8cd309551f25e3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0318 | Train Acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79e58ff8d1104026a1b2b0b1a584665f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0121 | Val Acc: 0.9975\n",
      "Epoch time: 295.42 seconds\n",
      "> Best model saved with validation accuracy 0.9975\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb421bdb9e344974a0356abaf41af97f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0026 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99b15212e94443678a9faab52d045cbe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0102 | Val Acc: 0.9979\n",
      "Epoch time: 295.90 seconds\n",
      "> Best model saved with validation accuracy 0.9979\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3db8a90bca945f3b981895ce063c557"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0008 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86b83914c8c24e48bd638b9940960423"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0107 | Val Acc: 0.9981\n",
      "Epoch time: 295.78 seconds\n",
      "> Best model saved with validation accuracy 0.9981\n",
      "Run time: 889.50 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4113a2bbb0f24994bb94484d07eb9570"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0335 | Train Acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b964afd0c4c24395961ef21c0bd557ff"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0110 | Val Acc: 0.9970\n",
      "Epoch time: 295.52 seconds\n",
      "> Best model saved with validation accuracy 0.9970\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "965edea862d1438e929f67504c992162"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0028 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dd1c7e6e3ae4e869c69fbf909538f1d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0085 | Val Acc: 0.9982\n",
      "Epoch time: 295.46 seconds\n",
      "> Best model saved with validation accuracy 0.9982\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71c3faca5d9343ee90d631f7b7fbae3e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0007 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6891225224d3407faa0900e53e6dbae9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0115 | Val Acc: 0.9972\n",
      "Epoch time: 295.47 seconds\n",
      "Run time: 888.36 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "feef642f9702487ca91b8bc937c6bf71"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0328 | Train Acc: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "633c77c6744443efa48e65af04eaae7e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0234 | Val Acc: 0.9942\n",
      "Epoch time: 295.68 seconds\n",
      "> Best model saved with validation accuracy 0.9942\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de38cc0b618f47c790c4996a7565f2d6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022 | Train Acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63f2b647d01245f19239f336df84db04"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0169 | Val Acc: 0.9973\n",
      "Epoch time: 295.79 seconds\n",
      "> Best model saved with validation accuracy 0.9973\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a00edd09d6c746b6850be7e202f418d6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0011 | Train Acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2def1ef4a4f546329e6f55ff18d7c3ea"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0124 | Val Acc: 0.9981\n",
      "Epoch time: 296.19 seconds\n",
      "> Best model saved with validation accuracy 0.9981\n",
      "Run time: 889.58 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "138c6382d5d74fcfbbe317ae29c7e8b2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0342 | Train Acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38374c97712b4551b4dc5676b75e8ca1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0110 | Val Acc: 0.9976\n",
      "Epoch time: 295.38 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "362e77da859b4606ac4cbe224d2938f6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0027 | Train Acc: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a2ef3daaa8d4590b01a83681d0b7f87"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0105 | Val Acc: 0.9975\n",
      "Epoch time: 296.18 seconds\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6de4a2dedbdf48b7b96800d00f4b92c2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0004 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "306ce1eaf88843758389006185cbbfe4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0128 | Val Acc: 0.9978\n",
      "Epoch time: 295.65 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Run time: 889.15 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2397c0f6114d4a55a6c811bf0163ca92"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0340 | Train Acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "163c3d814d6f4d948ed8c89ae01f066f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0265 | Val Acc: 0.9945\n",
      "Epoch time: 295.60 seconds\n",
      "> Best model saved with validation accuracy 0.9945\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4dcd73a8a00411e8330ed39a95ccd71"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0046 | Train Acc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a89d52214a14cd385b92082bda4700b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0120 | Val Acc: 0.9976\n",
      "Epoch time: 296.16 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6144aec322874807a229924889bd1d0e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0004 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "647d4ad7f8e64245b803bdac81549c75"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0093 | Val Acc: 0.9985\n",
      "Epoch time: 295.86 seconds\n",
      "> Best model saved with validation accuracy 0.9985\n",
      "Run time: 890.25 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 5\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ad90cc3f7104540afd6ed3264da0593"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0328 | Train Acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4079f5929d444cdb9ab543c2b5079c4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0109 | Val Acc: 0.9978\n",
      "Epoch time: 295.60 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f54d40dd2f9342658ae87d49417d8326"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0027 | Train Acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f99e02c1152466bbbb2ba25e9ce8b91"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0132 | Val Acc: 0.9978\n",
      "Epoch time: 294.93 seconds\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "463c15db176a47349f3cda66ff709539"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0004 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f30d803371544084a33d52f1fc2f780c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0117 | Val Acc: 0.9982\n",
      "Epoch time: 295.84 seconds\n",
      "> Best model saved with validation accuracy 0.9982\n",
      "Run time: 888.23 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_5_6.json\n",
      "============================================================\n",
      "Starting run for CONFIG 6 | epochs=3, lr=1.5e-05, wd=0.02, batch_size=32, device=cuda, max_length=128\n",
      "============================================================\n",
      "----------------------------------------\n",
      "Run 1/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ae3da3ea3c6469fa469a3af8a6ea6b1"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0423 | Train Acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbd48eb0c3b44e788c43c03f874c1667"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0176 | Val Acc: 0.9957\n",
      "Epoch time: 295.10 seconds\n",
      "> Best model saved with validation accuracy 0.9957\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0387a83a83843b2afacc6dd8fd1a494"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0035 | Train Acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7de4c27796f4975a5c378e867d42c17"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0119 | Val Acc: 0.9976\n",
      "Epoch time: 295.85 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ad22cbb17e04f3e9faa4ad0e7d956ee"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0006 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c7efb63b72049e5aa90b8ef508b3dae"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0127 | Val Acc: 0.9978\n",
      "Epoch time: 295.35 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Run time: 888.49 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_1.json\n",
      "----------------------------------------\n",
      "Run 2/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dd485fc8bd74c83a2af1743a523c9cf"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0434 | Train Acc: 0.9864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f31685fe07e44f53b5f9ec594d0e4437"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0152 | Val Acc: 0.9967\n",
      "Epoch time: 296.05 seconds\n",
      "> Best model saved with validation accuracy 0.9967\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baa84cbb743b4f96bba20e9ffc01ef47"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0033 | Train Acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05e2a3731aee41f0b58beb5e29a5c6c6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0150 | Val Acc: 0.9976\n",
      "Epoch time: 295.39 seconds\n",
      "> Best model saved with validation accuracy 0.9976\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09288a2c4ebf4ccc88f3814c2fc89dba"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005 | Train Acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caadd1d968af4307bb9cf60b77a2051b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0156 | Val Acc: 0.9973\n",
      "Epoch time: 295.77 seconds\n",
      "Run time: 889.29 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_2.json\n",
      "----------------------------------------\n",
      "Run 3/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29b8678c3c2b4684a85100e51a51e6d8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0466 | Train Acc: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1f8524ecd1d4977a67491dc0c06fe43"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0159 | Val Acc: 0.9963\n",
      "Epoch time: 296.36 seconds\n",
      "> Best model saved with validation accuracy 0.9963\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d97ca04fa2848c0ab546f15ce6431df"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0045 | Train Acc: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51a778c1f093471a824162f8fefe45d6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0138 | Val Acc: 0.9972\n",
      "Epoch time: 295.48 seconds\n",
      "> Best model saved with validation accuracy 0.9972\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e412f9d2fbe74b3982e1b7adebb30acc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7337e03a9c34f4da1d0de4cb20cb95e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0127 | Val Acc: 0.9978\n",
      "Epoch time: 295.74 seconds\n",
      "> Best model saved with validation accuracy 0.9978\n",
      "Run time: 890.31 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_3.json\n",
      "----------------------------------------\n",
      "Run 4/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b3d26bb3a724c87856e29d2269f46fc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0422 | Train Acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f93467a6521a454ba14226282ab6d0b6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0158 | Val Acc: 0.9961\n",
      "Epoch time: 296.23 seconds\n",
      "> Best model saved with validation accuracy 0.9961\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d72fb65ed7c445b91d04d349fc7e76b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0041 | Train Acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa9d23972a2849bbbe5310b4478f1ca2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0172 | Val Acc: 0.9967\n",
      "Epoch time: 295.73 seconds\n",
      "> Best model saved with validation accuracy 0.9967\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52198e8c0d1d4107b250300c3eb36b1b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010 | Train Acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb501dee29fc46dcbf19149a7030e3df"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0152 | Val Acc: 0.9970\n",
      "Epoch time: 295.31 seconds\n",
      "> Best model saved with validation accuracy 0.9970\n",
      "Run time: 889.72 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_4.json\n",
      "----------------------------------------\n",
      "Run 5/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e1f508738e247e2a251cc56ad96f000"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0462 | Train Acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e68272a7286416fb9cec6dced32b3c3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0161 | Val Acc: 0.9958\n",
      "Epoch time: 295.99 seconds\n",
      "> Best model saved with validation accuracy 0.9958\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7aeef903852c4d85b607f36c52005399"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0043 | Train Acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb5a347532ea4e3684bdf5204f549854"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0155 | Val Acc: 0.9973\n",
      "Epoch time: 295.69 seconds\n",
      "> Best model saved with validation accuracy 0.9973\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84432502e9e042e5b2b936c192eca64e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009 | Train Acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c34dc936b1b4fc98fc8919b60c37ed7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0128 | Val Acc: 0.9973\n",
      "Epoch time: 295.65 seconds\n",
      "Run time: 889.11 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_5.json\n",
      "----------------------------------------\n",
      "Run 6/5 for config 6\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 2949\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6860a21c063347e5a0051089a427b6e3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0427 | Train Acc: 0.9863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83509b472f324693b4ef1454ce4039af"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0266 | Val Acc: 0.9935\n",
      "Epoch time: 296.80 seconds\n",
      "> Best model saved with validation accuracy 0.9935\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf0b86909b5340699a0c016e301fa813"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0046 | Train Acc: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e10a522cb5d948a9b263f7f1383bb822"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0156 | Val Acc: 0.9975\n",
      "Epoch time: 296.12 seconds\n",
      "> Best model saved with validation accuracy 0.9975\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/983 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5815149390f4a46abc5c09447e069b9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005 | Train Acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5166876c4418481697e669ec4b3fd33f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0161 | Val Acc: 0.9970\n",
      "Epoch time: 295.71 seconds\n",
      "Run time: 890.30 seconds\n",
      "Saved results to DL_Milestone2_experiments\\run_6_6.json\n",
      "\n",
      "All configurations completed successfully!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "c09b443e",
   "metadata": {},
   "source": "## 8. Evaluating on the Test Set (only use after selecting the best configuration)"
  },
  {
   "cell_type": "code",
   "id": "0d5e347e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T10:31:31.929479Z",
     "start_time": "2025-11-20T10:31:31.926970Z"
    }
   },
   "source": [
    "# Test dataset and dataloader -> Creating the test dataset and dataloader\n",
    "\n",
    "print(\"Test samples:\", len(test_dataset))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 6735\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T10:36:26.232635Z",
     "start_time": "2025-11-20T10:36:25.230645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Choose which config/run you want to evaluate\n",
    "config_num = 3\n",
    "run = 1\n",
    "\n",
    "config_dir = OUTPUT_DIR / f\"cfg{config_num}\"\n",
    "best_model_path = config_dir / f\"bestmodel_{config_num}_run{run}.pt\"\n",
    "\n",
    "print(\"Loading model from:\", best_model_path)\n",
    "\n",
    "# Recreate the same architecture\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels = 2\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "state_dict = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "a71d9349b326bc9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: DL_Milestone2_experiments/cfg3/bestmodel_3_run1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T10:38:23.333015Z",
     "start_time": "2025-11-20T10:36:27.785795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on the test set\n",
    "test_acc, test_loss, y_true, y_pred = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ],
   "id": "e65b20294f711a3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/211 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb4054561e044184a66f21d491ed482e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2424 | Test Acc: 0.7451\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
